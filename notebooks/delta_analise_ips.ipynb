{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c1c3e02-7a3b-4477-ba23-5488c2139a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/28 14:44:11 WARN Utils: Your hostname, DESKTOP-1P6TETU resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/09/28 14:44:11 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/nice_correia/.cache/pypoetry/virtualenvs/trabalho-spark-RjY8yXlH-py3.12/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/nice_correia/.ivy2/cache\n",
      "The jars for the packages stored in: /home/nice_correia/.ivy2/jars\n",
      "io.delta#delta-spark_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-24289162-aa64-42f6-abfe-6d42e2f9616a;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.12;3.2.0 in central\n",
      "\tfound io.delta#delta-storage;3.2.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 342ms :: artifacts dl 13ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-spark_2.12;3.2.0 from central in [default]\n",
      "\tio.delta#delta-storage;3.2.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-24289162-aa64-42f6-abfe-6d42e2f9616a\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/10ms)\n",
      "25/09/28 14:44:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/09/28 14:44:19 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "25/09/28 14:44:19 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "25/09/28 14:44:22 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
      "25/09/28 14:44:22 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore nice_correia@127.0.1.1\n",
      "25/09/28 14:44:30 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider delta. Persisting data source table `spark_catalog`.`default`.`test_delta` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.\n",
      "25/09/28 14:44:31 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
      "25/09/28 14:44:31 WARN HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist\n",
      "25/09/28 14:44:31 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "25/09/28 14:44:31 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "25/09/28 14:44:32 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Suporte a Delta Lake confirmado! (JAR carregado e catálogo OK).\n",
      "SparkSession criada com sucesso! Versão: 3.5.7\n",
      "Catálogos disponíveis: ['spark_catalog']\n"
     ]
    }
   ],
   "source": [
    "# === SparkSession Setup (Foco em Delta Lake - Sem Conflito com Iceberg) ===\n",
    "import shutil\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Cria SparkSession OTIMIZADA para Delta (sem Iceberg para evitar conflitos estáticos)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DeltaLake_ETL_IPS\") \\\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-spark_2.12:3.2.0\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Log level logo após criação (reduz spam)\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "# Verificação IMEDIATA: Confirma suporte Delta (antes de qualquer config extra)\n",
    "try:\n",
    "    spark.sql(\"CREATE TABLE IF NOT EXISTS spark_catalog.default.test_delta (id INT) USING DELTA\")\n",
    "    spark.sql(\"DROP TABLE spark_catalog.default.test_delta\")\n",
    "    print(\"✅ Suporte a Delta Lake confirmado! (JAR carregado e catálogo OK).\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Erro no Delta: {e} - Verifique instalação do JAR ou reinicie o kernel.\")\n",
    "\n",
    "print(\"SparkSession criada com sucesso! Versão:\", spark.version)\n",
    "print(\"Catálogos disponíveis:\", [c.name for c in spark.catalog.listCatalogs()])\n",
    "\n",
    "# Opcional: Se quiser adicionar configs Iceberg DINÂMICAS (não estáticas), faça aqui - mas sem extensions/catalog\n",
    "# Ex: spark.conf.set(\"spark.sql.catalog.iceberg_catalog.warehouse\", \"/tmp/iceberg\")  # Só se não conflitar\n",
    "# Para Iceberg full, reinicie e use config no builder (veja abaixo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c76824a6-ade0-42cd-9505-09fdaafaa716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta ETL completo e limpo!\n"
     ]
    }
   ],
   "source": [
    "# Cleanup rápido (rode se der erro)\n",
    "spark.sql(\"DROP TABLE IF EXISTS delta_ips\")\n",
    "shutil.rmtree(\"/tmp/delta\", ignore_errors=True)\n",
    "os.makedirs(\"/tmp/delta\", exist_ok=True)\n",
    "print(\"Delta ETL completo e limpo!\")\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "518b4dc0-e301-4c93-a46e-8d8179b1a660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caminho CSV: /home/nice_correia/trabalho_spark/data/raw/ips_brasil.csv (existe? True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF carregado: 5570 linhas, 79 colunas.\n",
      "+-----------+--------------------------+---+--------------------------+\n",
      "|Código IBGE|Município                 |UF |Índice de Progresso Social|\n",
      "+-----------+--------------------------+---+--------------------------+\n",
      "|1100015    |Alta Floresta D'Oeste (RO)|RO |50.94710852687823         |\n",
      "|1100023    |Ariquemes (RO)            |RO |55.97475391330499         |\n",
      "|1100031    |Cabixi (RO)               |RO |51.36453973053614         |\n",
      "|1100049    |Cacoal (RO)               |RO |61.84526595721548         |\n",
      "|1100056    |Cerejeiras (RO)           |RO |58.70878800673873         |\n",
      "+-----------+--------------------------+---+--------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Detecta caminho do CSV (ajuste se necessário - assume notebooks/ no root do projeto)\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.dirname(notebook_dir) if \"notebooks\" in notebook_dir else notebook_dir\n",
    "raw_path = os.path.join(project_root, \"data\", \"raw\", \"ips_brasil.csv\")\n",
    "\n",
    "print(f\"Caminho CSV: {raw_path} (existe? {os.path.exists(raw_path)})\")\n",
    "\n",
    "if os.path.exists(raw_path):\n",
    "    df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(raw_path)\n",
    "    print(f\"DF carregado: {df.count()} linhas, {len(df.columns)} colunas.\")\n",
    "    df.select(\"`Código IBGE`\", \"`Município`\", \"`UF`\", \"`Índice de Progresso Social`\").show(5, truncate=False)\n",
    "else:\n",
    "    print(\"❌ CSV não encontrado! Verifique path ou baixe ips_brasil.csv para data/raw/.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04e119f5-841e-4b93-9389-5a93615d3e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Delta Lake: DDL ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/28 14:09:11 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "25/09/28 14:09:16 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider delta. Persisting data source table `spark_catalog`.`default`.`delta_ips` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela Delta criada com sucesso! (Column mapping habilitado para nomes especiais).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de linhas na tabela: 5570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+---+--------------------------+\n",
      "|Código IBGE|Município          |UF |Índice de Progresso Social|\n",
      "+-----------+-------------------+---+--------------------------+\n",
      "|3516853    |Gavião Peixoto (SP)|SP |74.49282395600983         |\n",
      "|5300108    |Brasília (DF)      |DF |71.25189747327438         |\n",
      "|3548906    |São Carlos (SP)    |SP |70.96059545595044         |\n",
      "|5208707    |Goiânia (GO)       |GO |70.49282747376537         |\n",
      "|3533601    |Nuporanga (SP)     |SP |70.4719550872065          |\n",
      "+-----------+-------------------+---+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === Delta Lake: DDL (Criação da Tabela) ===\n",
    "print(\"\\n=== Delta Lake: DDL ===\")\n",
    "delta_path = \"/tmp/delta/ips\"\n",
    "\n",
    "# Limpa tabela se existir (opcional, overwrite cuida disso)\n",
    "spark.sql(f\"DROP TABLE IF EXISTS delta_ips\")\n",
    "\n",
    "# Escreve o DataFrame como Delta com column mapping (para nomes especiais como 'Código IBGE')\n",
    "df.write.format(\"delta\").mode(\"overwrite\").option(\"delta.columnMapping.mode\", \"name\").save(delta_path)\n",
    "\n",
    "# Registra como tabela gerenciada (habilita SQL queries)\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS delta_ips\n",
    "    USING DELTA\n",
    "    LOCATION '{delta_path}'\n",
    "    TBLPROPERTIES ('delta.columnMapping.mode' = 'name')\n",
    "\"\"\")\n",
    "\n",
    "print(\"Tabela Delta criada com sucesso! (Column mapping habilitado para nomes especiais).\")\n",
    "print(f\"Total de linhas na tabela: {spark.sql('SELECT COUNT(*) FROM delta_ips').collect()[0][0]}\")\n",
    "\n",
    "# Verificação rápida: Mostra as top 5 linhas originais\n",
    "spark.sql(\"SELECT `Código IBGE`, `Município`, `UF`, `Índice de Progresso Social` FROM delta_ips ORDER BY `Índice de Progresso Social` DESC LIMIT 5\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1d478a8-437f-4379-ac36-0b383c49cbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Delta Lake: INSERT ===\n",
      "INSERT: Linha fictícia adicionada com sucesso!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+---+--------------------------+\n",
      "|Código IBGE|Município          |UF |Índice de Progresso Social|\n",
      "+-----------+-------------------+---+--------------------------+\n",
      "|9999999    |Exemplo Fictício   |XX |99.0                      |\n",
      "|3516853    |Gavião Peixoto (SP)|SP |74.49282395600983         |\n",
      "|5300108    |Brasília (DF)      |DF |71.25189747327438         |\n",
      "|3548906    |São Carlos (SP)    |SP |70.96059545595044         |\n",
      "|5208707    |Goiânia (GO)       |GO |70.49282747376537         |\n",
      "+-----------+-------------------+---+--------------------------+\n",
      "\n",
      "Total de linhas após INSERT: 5571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# === Delta Lake: INSERT ===\n",
    "print(\"\\n=== Delta Lake: INSERT ===\")\n",
    "\n",
    "# INSERT via SQL (só preenche colunas chave; o resto fica NULL ou default)\n",
    "spark.sql(\"INSERT INTO delta_ips (`Código IBGE`, `Município`, `UF`, `Índice de Progresso Social`) VALUES ('9999999', 'Exemplo Fictício', 'XX', 99.0)\")\n",
    "\n",
    "print(\"INSERT: Linha fictícia adicionada com sucesso!\")\n",
    "\n",
    "# Verificação: Top 5 linhas ordenadas por IPS (deve incluir a nova no topo)\n",
    "spark.sql(\"SELECT `Código IBGE`, `Município`, `UF`, `Índice de Progresso Social` FROM delta_ips ORDER BY `Índice de Progresso Social` DESC LIMIT 5\").show(truncate=False)\n",
    "\n",
    "# Conta total (deve ser +1)\n",
    "print(f\"Total de linhas após INSERT: {spark.sql('SELECT COUNT(*) FROM delta_ips').collect()[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32dcdc74-0255-430d-aa5b-bbbf535eb98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Delta Lake: UPDATE ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDATE: IPS aumentado em +1 para Alta Floresta D'Oeste (código 1100015)!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------------+--------------------------+\n",
      "|Código IBGE|Município                 |Índice de Progresso Social|\n",
      "+-----------+--------------------------+--------------------------+\n",
      "|1100015    |Alta Floresta D'Oeste (RO)|51.94710852687823         |\n",
      "+-----------+--------------------------+--------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 53:===============================================>        (42 + 7) / 50]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPS original (do DF): 50.94710852687823 | IPS atualizado (na tabela): 51.94710852687823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# === Delta Lake: UPDATE ===\n",
    "print(\"\\n=== Delta Lake: UPDATE ===\")\n",
    "\n",
    "# UPDATE via SQL (aumenta IPS em +1 para o município específico)\n",
    "spark.sql(\"UPDATE delta_ips SET `Índice de Progresso Social` = `Índice de Progresso Social` + 1 WHERE `Código IBGE` = '1100015'\")\n",
    "\n",
    "print(\"UPDATE: IPS aumentado em +1 para Alta Floresta D'Oeste (código 1100015)!\")\n",
    "\n",
    "# Verificação: Mostra a linha atualizada\n",
    "spark.sql(\"SELECT `Código IBGE`, `Município`, `Índice de Progresso Social` FROM delta_ips WHERE `Código IBGE` = '1100015'\").show(truncate=False)\n",
    "\n",
    "# Opcional: Verifica se mudou (compara com valor original do df, se quiser)\n",
    "original_ips = df.filter(\"`Código IBGE` = '1100015'\").select(\"`Índice de Progresso Social`\").collect()[0][0]\n",
    "print(f\"IPS original (do DF): {original_ips} | IPS atualizado (na tabela): {spark.sql('SELECT `Índice de Progresso Social` FROM delta_ips WHERE `Código IBGE` = \\\"1100015\\\"').collect()[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6d2e276-eb6c-418a-8b3d-a3a7af142750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Delta Lake: Time Travel ===\n",
      "Versões disponíveis:\n",
      "+-------+-----------------------+---------+\n",
      "|version|timestamp              |operation|\n",
      "+-------+-----------------------+---------+\n",
      "|2      |2025-09-28 14:10:22.891|UPDATE   |\n",
      "|1      |2025-09-28 14:09:51.947|WRITE    |\n",
      "|0      |2025-09-28 14:09:15.965|WRITE    |\n",
      "+-------+-----------------------+---------+\n",
      "\n",
      "Time Travel: Versão inicial (versão 0 - antes de UPDATE/DELETE).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------------+---+--------------------------+\n",
      "|Código IBGE|Município                 |UF |Índice de Progresso Social|\n",
      "+-----------+--------------------------+---+--------------------------+\n",
      "|1100015    |Alta Floresta D'Oeste (RO)|RO |50.94710852687823         |\n",
      "+-----------+--------------------------+---+--------------------------+\n",
      "\n",
      "Estado ATUAL (após UPDATE):\n",
      "+-----------+--------------------------+--------------------------+\n",
      "|Código IBGE|Município                 |Índice de Progresso Social|\n",
      "+-----------+--------------------------+--------------------------+\n",
      "|1100015    |Alta Floresta D'Oeste (RO)|51.94710852687823         |\n",
      "+-----------+--------------------------+--------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# === Delta Lake: Time Travel ===\n",
    "print(\"\\n=== Delta Lake: Time Travel ===\")\n",
    "\n",
    "# Lista versões disponíveis (opcional: para ver histórico)\n",
    "print(\"Versões disponíveis:\")\n",
    "spark.sql(\"DESCRIBE HISTORY delta_ips\").select(\"version\", \"timestamp\", \"operation\").show(10, truncate=False)\n",
    "\n",
    "# Time Travel: Recupera versão 0 (dados originais, antes de qualquer DML)\n",
    "print(\"Time Travel: Versão inicial (versão 0 - antes de UPDATE/DELETE).\")\n",
    "spark.sql(\"SELECT `Código IBGE`, `Município`, `UF`, `Índice de Progresso Social` FROM delta_ips VERSION AS OF 0 WHERE `Código IBGE` = '1100015'\").show(truncate=False)\n",
    "\n",
    "# Compara com estado atual (deve mostrar IPS original vs. atualizado)\n",
    "print(\"Estado ATUAL (após UPDATE):\")\n",
    "spark.sql(\"SELECT `Código IBGE`, `Município`, `Índice de Progresso Social` FROM delta_ips WHERE `Código IBGE` = '1100015'\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d86fc8a-d2bf-4a8c-addf-a5c1f322f299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Delta Lake: DELETE ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELETE: Linha fictícia removida com sucesso!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+---+--------------------------+\n",
      "|Código IBGE|Município          |UF |Índice de Progresso Social|\n",
      "+-----------+-------------------+---+--------------------------+\n",
      "|3516853    |Gavião Peixoto (SP)|SP |74.49282395600983         |\n",
      "|5300108    |Brasília (DF)      |DF |71.25189747327438         |\n",
      "|3548906    |São Carlos (SP)    |SP |70.96059545595044         |\n",
      "|5208707    |Goiânia (GO)       |GO |70.49282747376537         |\n",
      "|3533601    |Nuporanga (SP)     |SP |70.4719550872065          |\n",
      "+-----------+-------------------+---+--------------------------+\n",
      "\n",
      "Total de linhas após DELETE: 5570\n"
     ]
    }
   ],
   "source": [
    "# === Delta Lake: DELETE ===\n",
    "print(\"\\n=== Delta Lake: DELETE ===\")\n",
    "\n",
    "# DELETE via SQL (remove a linha fictícia pelo código único)\n",
    "spark.sql(\"DELETE FROM delta_ips WHERE `Código IBGE` = '9999999'\")\n",
    "\n",
    "print(\"DELETE: Linha fictícia removida com sucesso!\")\n",
    "\n",
    "# Verificação: Top 5 linhas (não deve mais incluir a fictícia)\n",
    "spark.sql(\"SELECT `Código IBGE`, `Município`, `UF`, `Índice de Progresso Social` FROM delta_ips ORDER BY `Índice de Progresso Social` DESC LIMIT 5\").show(truncate=False)\n",
    "\n",
    "# Conta total (deve voltar ao original, -1 do INSERT)\n",
    "print(f\"Total de linhas após DELETE: {spark.sql('SELECT COUNT(*) FROM delta_ips').collect()[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc1024c2-26e5-4e57-87d2-ced28631af22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Delta Lake: Time Travel ===\n",
      "Histórico de Versões (operação, timestamp e params):\n",
      "+-------+-----------------------+---------+-----------------------------------------------+\n",
      "|version|timestamp              |operation|operationParameters                            |\n",
      "+-------+-----------------------+---------+-----------------------------------------------+\n",
      "|3      |2025-09-28 14:11:08.592|DELETE   |{predicate -> [\"(Código IBGE#7695 = 9999999)\"]}|\n",
      "|2      |2025-09-28 14:10:22.891|UPDATE   |{predicate -> [\"(Código IBGE#4686 = 1100015)\"]}|\n",
      "|1      |2025-09-28 14:09:51.947|WRITE    |{mode -> Append, partitionBy -> []}            |\n",
      "|0      |2025-09-28 14:09:15.965|WRITE    |{mode -> Overwrite, partitionBy -> []}         |\n",
      "+-------+-----------------------+---------+-----------------------------------------------+\n",
      "\n",
      "Total de versões: 4 (esperado: 4 após DDL/INSERT/UPDATE/DELETE)\n",
      "\n",
      "1. Versão INICIAL (v0 - após DDL, antes INSERT/UPDATE/DELETE):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------------+---+--------------------------+\n",
      "|Código IBGE|Município                 |UF |Índice de Progresso Social|\n",
      "+-----------+--------------------------+---+--------------------------+\n",
      "|1100015    |Alta Floresta D'Oeste (RO)|RO |50.94710852687823         |\n",
      "+-----------+--------------------------+---+--------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Linhas totais: 5570 (dados CSV originais)\n",
      "   Observação: Sem fictícia (9999999) e IPS original de Alta Floresta (~60-70)\n",
      "\n",
      "2. Após INSERT (v1 - fictícia adicionada, antes UPDATE/DELETE):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------------+---+--------------------------+\n",
      "|Código IBGE|Município                 |UF |Índice de Progresso Social|\n",
      "+-----------+--------------------------+---+--------------------------+\n",
      "|9999999    |Exemplo Fictício          |XX |99.0                      |\n",
      "|1100015    |Alta Floresta D'Oeste (RO)|RO |50.94710852687823         |\n",
      "+-----------+--------------------------+---+--------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Linhas totais: 5571 (+1 da fictícia 9999999 no topo com IPS 99.9)\n",
      "\n",
      "3. Após UPDATE, ANTES DELETE (v2 - UPDATE aplicado, fictícia ainda OK):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------------+---+--------------------------+\n",
      "|Código IBGE|Município                 |UF |Índice de Progresso Social|\n",
      "+-----------+--------------------------+---+--------------------------+\n",
      "|9999999    |Exemplo Fictício          |XX |99.0                      |\n",
      "|1100015    |Alta Floresta D'Oeste (RO)|RO |51.94710852687823         |\n",
      "+-----------+--------------------------+---+--------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Linhas totais: 5571 (mesmo que após INSERT; só IPS de 1100015 = 70.5)\n",
      "   Observação: Fictícia (9999999) ainda existe; Alta Floresta atualizada\n",
      "\n",
      "4. Após DELETE (v3 - atual, fictícia removida):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------------+---+--------------------------+\n",
      "|Código IBGE|Município                 |UF |Índice de Progresso Social|\n",
      "+-----------+--------------------------+---+--------------------------+\n",
      "|1100015    |Alta Floresta D'Oeste (RO)|RO |51.94710852687823         |\n",
      "+-----------+--------------------------+---+--------------------------+\n",
      "\n",
      "   Linhas totais: 5570 (-1 da fictícia; volta ao original)\n",
      "   Observação: Fictícia (9999999) sumiu; Alta Floresta mantém IPS 70.5 (UPDATE intacto)\n",
      "\n",
      "Resumo de Mudanças:\n",
      "   Inicial (v0): 5570 linhas\n",
      "   Após INSERT (v1): 5571 linhas (+1)\n",
      "   Após UPDATE (v2): 5571 linhas (sem mudança de contagem)\n",
      "   Após DELETE (v3): 5570 linhas (-1, volta ao inicial)\n",
      "\n",
      "Time Travel Delta completo! Histórico imutável - DELETE removeu fictícia, mas UPDATE persiste em versões futuras.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# === Delta Lake: Time Travel (Completo: Antes/Depois de INSERT, UPDATE e DELETE) ===\n",
    "print(\"\\n=== Delta Lake: Time Travel ===\")\n",
    "table_name = \"spark_catalog.default.delta_ips\"  # Full name; mude para \"delta_ips\" se alias\n",
    "\n",
    "# Lista histórico completo (versões disponíveis)\n",
    "print(\"Histórico de Versões (operação, timestamp e params):\")\n",
    "history_df = spark.sql(f\"DESCRIBE HISTORY {table_name}\")\n",
    "history_df.select(\"version\", \"timestamp\", \"operation\", \"operationParameters\").show(truncate=False, n=10)\n",
    "total_versions = history_df.count()\n",
    "print(f\"Total de versões: {total_versions} (esperado: 4 após DDL/INSERT/UPDATE/DELETE)\")\n",
    "\n",
    "if total_versions < 2:\n",
    "    print(\"⚠️ Poucas versões - rode mais DMLs (INSERT/UPDATE/DELETE) para demo completa.\")\n",
    "else:\n",
    "    # Extrai IDs de versões chave (baseado em histórico típico: v0=DDL, v1=INSERT, v2=UPDATE, v3=DELETE)\n",
    "    versions = history_df.select(\"version\").orderBy(\"version\").collect()\n",
    "    v0 = versions[0][0] if len(versions) > 0 else 0\n",
    "    v1_insert = versions[1][0] if len(versions) > 1 else None  # Após INSERT\n",
    "    v2_update = versions[2][0] if len(versions) > 2 else None  # Após UPDATE (antes DELETE)\n",
    "    v3_delete = versions[3][0] if len(versions) > 3 else None  # Após DELETE (atual)\n",
    "\n",
    "    # Função auxiliar para query em versão específica\n",
    "    def query_version(version, limit=1):\n",
    "        return spark.sql(f\"\"\"\n",
    "            SELECT `Código IBGE`, `Município`, `UF`, `Índice de Progresso Social` \n",
    "            FROM {table_name} VERSION AS OF {version} \n",
    "            WHERE `Código IBGE` IN ('9999999', '1100015')  -- Fictícia + Alta Floresta\n",
    "            ORDER BY `Índice de Progresso Social` DESC\n",
    "        \"\"\")\n",
    "\n",
    "    # 1. Versão Inicial (v0: Antes de qualquer DML - só dados originais)\n",
    "    print(f\"\\n1. Versão INICIAL (v{v0} - após DDL, antes INSERT/UPDATE/DELETE):\")\n",
    "    initial_df = query_version(v0)\n",
    "    initial_df.show(truncate=False)\n",
    "    initial_count = spark.sql(f\"SELECT COUNT(*) FROM {table_name} VERSION AS OF {v0}\").collect()[0][0]\n",
    "    print(f\"   Linhas totais: {initial_count} (dados CSV originais)\")\n",
    "    print(\"   Observação: Sem fictícia (9999999) e IPS original de Alta Floresta (~60-70)\")\n",
    "\n",
    "    # 2. Após INSERT (v1: Com linha fictícia adicionada)\n",
    "    if v1_insert:\n",
    "        print(f\"\\n2. Após INSERT (v{v1_insert} - fictícia adicionada, antes UPDATE/DELETE):\")\n",
    "        insert_df = query_version(v1_insert)\n",
    "        insert_df.show(truncate=False)\n",
    "        insert_count = spark.sql(f\"SELECT COUNT(*) FROM {table_name} VERSION AS OF {v1_insert}\").collect()[0][0]\n",
    "        print(f\"   Linhas totais: {insert_count} (+1 da fictícia 9999999 no topo com IPS 99.9)\")\n",
    "    else:\n",
    "        print(\"\\n2. Pulando após INSERT (versão não encontrada)\")\n",
    "\n",
    "    # 3. Após UPDATE, Antes DELETE (v2: Fictícia ainda presente, mas Alta Floresta atualizada)\n",
    "    if v2_update:\n",
    "        print(f\"\\n3. Após UPDATE, ANTES DELETE (v{v2_update} - UPDATE aplicado, fictícia ainda OK):\")\n",
    "        update_df = query_version(v2_update)\n",
    "        update_df.show(truncate=False)\n",
    "        update_count = spark.sql(f\"SELECT COUNT(*) FROM {table_name} VERSION AS OF {v2_update}\").collect()[0][0]\n",
    "        print(f\"   Linhas totais: {update_count} (mesmo que após INSERT; só IPS de 1100015 = 70.5)\")\n",
    "        print(\"   Observação: Fictícia (9999999) ainda existe; Alta Floresta atualizada\")\n",
    "    else:\n",
    "        print(\"\\n3. Pulando após UPDATE (versão não encontrada)\")\n",
    "\n",
    "    # 4. Após DELETE (v3/Atual: Fictícia removida, UPDATE preservado)\n",
    "    current_version = history_df.orderBy(\"version\", ascending=False).collect()[0][0]  # Última versão\n",
    "    print(f\"\\n4. Após DELETE (v{current_version} - atual, fictícia removida):\")\n",
    "    delete_df = query_version(current_version)\n",
    "    delete_df.show(truncate=False)\n",
    "    current_count = spark.sql(f\"SELECT COUNT(*) FROM {table_name}\").collect()[0][0]\n",
    "    print(f\"   Linhas totais: {current_count} (-1 da fictícia; volta ao original)\")\n",
    "    print(\"   Observação: Fictícia (9999999) sumiu; Alta Floresta mantém IPS 70.5 (UPDATE intacto)\")\n",
    "\n",
    "    # Comparação Geral: Diferenças de contagem\n",
    "    if v1_insert and v3_delete:\n",
    "        print(f\"\\nResumo de Mudanças:\")\n",
    "        print(f\"   Inicial (v{v0}): {initial_count} linhas\")\n",
    "        print(f\"   Após INSERT (v{v1_insert}): {insert_count} linhas (+1)\")\n",
    "        print(f\"   Após UPDATE (v{v2_update}): {update_count} linhas (sem mudança de contagem)\")\n",
    "        print(f\"   Após DELETE (v{current_version}): {current_count} linhas (-1, volta ao inicial)\")\n",
    "\n",
    "# Opcional: Rollback para versão antes do DELETE (ex: v2 - desfaz DELETE, fictícia volta)\n",
    "# print(\"\\nTeste Opcional: Rollback para antes do DELETE (cuidado - altera atual!)\")\n",
    "# if v2_update:\n",
    "#     spark.sql(f\"RESTORE TABLE {table_name} TO VERSION AS OF {v2_update}\")\n",
    "#     print(f\"Rollback executado para v{v2_update}! Agora fictícia voltou - verifique COUNT(*): {spark.sql(f'SELECT COUNT(*) FROM {table_name}').collect()[0][0]}\")\n",
    "#     # Para reverter rollback: RESTORE TO VERSION AS OF {current_version}\n",
    "\n",
    "print(\"\\nTime Travel Delta completo! Histórico imutável - DELETE removeu fictícia, mas UPDATE persiste em versões futuras.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c43cc17-95fb-4d81-a5f3-acd2e60ebf00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
